#
# Created by MikBac on 30.08.2025
#
# Docs:
#   * https://docs.confluent.io/platform/current/installation/configuration/broker-configs.html
#   * https://docs.confluent.io/platform/current/installation/docker/config-reference.html
#   * https://akhq.io/
services:
  kafka-confluent:
    image: confluentinc/cp-kafka:7.9.2 # Apache Kafka 3.9
    hostname: confluent-kafka
    restart: unless-stopped
    ports:
      - '9192:9092'
    volumes:
      - kafka-storage:/var/lib/kafka/data
    environment:
      # KRaft mode
      # Enable KRaft mode (instead of Zookeeper mode).
      - KAFKA_KRAFT_MODE=true
      # Comma-separated list of Kafka KRaft roles. Allowed values: "controller,broker", "controller", "broker".
      - KAFKA_PROCESS_ROLES=broker,controller
      # Unique id for the Kafka node. It has to be an integer.
      - KAFKA_NODE_ID=1
      # Comma separated host:port pairs, each corresponding to a Kafka controller connection.
      # Pattern: <controller1_node_id>@<controller1_host>:9093
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@confluent-kafka:9093
      # A string that specifies the unique identifier for the Replicator cluster
      - CLUSTER_ID=rwJnBJlxJUaYNBpgdpahcx
      # -----------
      # Listeners & protocols
      # List of Kafka listeners. If node is set with controller role, the listener CONTROLLER must be included.
      - KAFKA_LISTENERS=EXTERNAL://:9092,CONTROLLER://:9093,INTERNAL://:9094
      # Maps each listener with Apache Kafka security protocol. Allowed values: PLAINTEXT, SSL, SASL_PLAINTEXT, SASL_SSL
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT,INTERNAL:PLAINTEXT
      # Address map for external connection to Kafka.
      # E.g. EXTERNAL is the external address and INTERNAL is the address available inside the docker network.
      - KAFKA_ADVERTISED_LISTENERS=EXTERNAL://localhost:9192,INTERNAL://confluent-kafka:9094
      # Name of internal listener. An internal broker used for communication between brokers.
      - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL
      # Name of controller listener.
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      # -----------
      # Broker configs
      # Log retention policy (e.g. 48 is 2 days retention).
      # Available log retentions policies:
      #   * KAFKA_CFG_LOG_RETENTION_HOURS
      #   * KAFKA_CFG_LOG_RETENTION_CHECK_INTERVAL_MS
      #   * KAFKA_CFG_LOG_RETENTION_BYTES
      - KAFKA_LOG_RETENTION_HOURS=48
      # Default replication factors for automatically created topics.
      - KAFKA_DEFAULT_REPLICATION_FACTOR=1
      # The replication factor for the offsets topic (set higher to ensure availability).
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      # The replication factor for the transaction topic (set higher to ensure availability).
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      # Automatically creates a topic when subscribing or assigning a non-existent topic.
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=false
      # Rack of the broker. This will be used in rack aware replication assignment for fault tolerance.
      # E.g. RACK1, us-east-1d
      # The Rack Awareness feature in Kafka spreads replicas of the same partition across different racks
      # to minimize data loss in the event of a rack failure.
      - KAFKA_BROKER_RACK=zone-test
      # -----------
      # Storage dir
      - KAFKA_LOG_DIRS=/var/lib/kafka/data
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 1g
    networks:
      - kafka-network
  akhq-ui:
    image: tchiotludo/akhq:0.26.0
    restart: unless-stopped
    ports:
      - '9080:8080'
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            kafka-cluster:
              properties:
                bootstrap.servers: "confluent-kafka:9094"
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: 512M
    networks:
      - kafka-network
    depends_on:
      - kafka-confluent

volumes:
  kafka-storage:
    driver: local

networks:
  kafka-network:
